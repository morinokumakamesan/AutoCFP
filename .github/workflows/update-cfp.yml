name: Update CFP Data

on:
  schedule:
    # Run twice a month: 1st and 15th at 00:00 UTC (09:00 JST)
    - cron: '0 0 1,15 * *'
  workflow_dispatch:  # Allow manual trigger

jobs:
  update-data:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Allow workflow to commit and push changes

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Install uv
      uses: astral-sh/setup-uv@v5
      with:
        enable-cache: true

    - name: Install dependencies
      run: |
        uv sync

    # Note: We don't run parse_conferences.py here because:
    # - conferences_base.json is already committed to the repository
    # - CSV file contains sensitive data and is not in version control
    # - This workflow only updates CFP information from WikiCFP
    - name: Scrape CFP information
      run: |
        uv run python scripts/scrape_cfp.py
      continue-on-error: true  # Continue even if some scraping fails

    - name: Commit and push if changed
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add public/data/*.json
        git diff --quiet && git diff --staged --quiet || (git commit -m "Update CFP data [automated]" && git push)

  deploy:
    needs: update-data
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pages: write
      id-token: write

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        ref: main  # Ensure we get the latest commit from main branch

    - name: Pull latest changes
      run: git pull origin main

    - name: Setup Pages
      uses: actions/configure-pages@v5

    - name: Upload artifact
      uses: actions/upload-pages-artifact@v3
      with:
        path: './public'

    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4
